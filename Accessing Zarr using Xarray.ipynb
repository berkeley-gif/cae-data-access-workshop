{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa64b51d-2362-4427-8b38-c8dc9d0d0635",
   "metadata": {},
   "source": [
    "# Accessing Zarr data using Xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49fd118-ad14-429c-a17c-8cbe781229fe",
   "metadata": {},
   "source": [
    "First we import **xarray**, a multi dimensional array processing package. It can open netCDF as well as Zarr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb269997-676b-4bb7-ba8a-bd2e3f046d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a90be43-4310-4793-8880-abb46920537a",
   "metadata": {},
   "source": [
    "We then use the **open_zarr()** command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5d503-f805-4285-a9c4-aeee9d03cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr('wrf/ucla/cesm2/ssp370/mon/t2/d01')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e50f68-b770-4a8e-9ba2-768f8ffc088f",
   "metadata": {},
   "source": [
    "The dataset is now a Python object and you can see the coordinates: x, y and time. Looking at the x and y you can see that they are large numbers. That is because WRF is stored in a custom Lambert Conformal Conic projection, whereas the LOCA2 data are stored in lat and long. In order to use lat and long we need to transform the coordinate into the correct projection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b52e6-7053-411b-909a-8f8e63764ade",
   "metadata": {},
   "source": [
    "We can use these packages and code to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79214aa0-4722-46a7-a6eb-8377314f719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rio\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b7057b-c5f1-4ae7-b713-4080b56a0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform the coordinates\n",
    "ll_to_lambert = pyproj.Transformer.from_crs(crs_from=\"epsg:4326\", crs_to=ds.rio.crs, always_xy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845f1917-b6b8-4d92-bd5e-ef656c9bfe50",
   "metadata": {},
   "source": [
    "The Lambert projection info is stored as an attribute of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc697a99-bca0-48f7-8a30-fb3ba1bbbb29",
   "metadata": {},
   "source": [
    "Now we can look at the values for the dataset at Sacramentoâ€™s lat and long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8a316c-d23b-4cec-96aa-879271fc1c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show values at Sacramento\n",
    "x, y = ll_to_lambert.transform(-121.23, 38.33)\n",
    "ds['t2'].sel(x=x, y=y, method='nearest').values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ed649-d19f-4db1-931d-3efb257c34f3",
   "metadata": {},
   "source": [
    "The temperature values are in Kelvin for each of the time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce108c39-5afe-446c-bd1a-1a7db67e5bc5",
   "metadata": {},
   "source": [
    "We can do the same for Los Angeles and see that the values are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218aa2fc-ec4b-4327-a2c4-20a4a1f87228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show values at Los Angeles\n",
    "x, y = ll_to_lambert.transform(-118.24, 34.05)\n",
    "ds['t2'].sel(x=x, y=y, method='nearest').values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711db2d-90d7-471c-acf0-ad5a5004154e",
   "metadata": {},
   "source": [
    "Instead of downloading the data we can actually load it directly from S3, using the same command but instead using the S3 path to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615db690-969b-4ced-96a8-994233be0e00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(\n",
    "'s3://cadcat/wrf/ucla/cesm2/ssp370/mon/t2/d01/', storage_options={'anon': True}\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f58ecd-92e4-48bd-95ff-5e1ba1c63a20",
   "metadata": {},
   "source": [
    "We can then run the same commands and get the same answers but without actually downloading the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6968752b-79dc-4ea9-914e-d7fc086f8da1",
   "metadata": {},
   "source": [
    "Let's get Los Angeles data from S3 directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03726d3-ffaa-4ec6-a7cd-3acb76fb873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show values at Los Angeles\n",
    "x, y = ll_to_lambert.transform(-118.24, 34.05)\n",
    "ds['t2'].sel(x=x, y=y, method='nearest').values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86499f6-5e87-44ad-b0f8-db6acef13c3e",
   "metadata": {},
   "source": [
    "This covers the basics of using the AWS CLI to download Analytics Engine data from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3375b1-14fc-4cc5-b8f0-98ba4f447c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
